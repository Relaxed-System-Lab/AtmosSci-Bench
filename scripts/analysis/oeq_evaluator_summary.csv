model,overall_accuracy,num_subquestions,quantity_true,quantity_false,quantity_null,quantity_coverage,expression_true,expression_false,expression_null,expression_coverage,llm_true,llm_false,llm_null,llm_coverage
openai-gpt4o-8000,0.22506393861892582,625,56,180,344,0.3776,36,463,25,0.8769771528998243,23,506,4,0.9924953095684803
google-GeminiModel-30000,0,0,0,0,0,0,0,0,0,0,0,0,0,0
openai-o3-mini-8000,0,0,0,0,0,0,0,0,0,0,0,0,0,0
google-gemini-2.0-flash-thinking-exp-01-21-30000,0.3145780051150895,559,82,156,321,0.4257602862254025,49,369,59,0.8763102725366876,43,384,1,0.9976635514018691
together-QwQ-32B-Preview-30000,0.24552429667519182,625,70,199,302,0.4304,29,426,46,0.8198198198198198,32,493,1,0.9980988593155894
openai-o3-mini-30000,0.3375959079283887,597,80,212,305,0.48911222780569513,54,441,22,0.9574468085106383,54,407,2,0.9956803455723542
together-Qwen2.5-72B-GeoGPT-8000,0,0,0,0,0,0,0,0,0,0,0,0,0,0
together-Qwen2.5-72B-Instruct-Turbo-8000,0.24040920716112532,625,58,241,294,0.4784,36,477,22,0.9047619047619048,28,502,1,0.9981167608286252
openai-o1-30000,0.3171355498721228,625,97,161,342,0.4128,41,440,22,0.9109848484848485,46,438,3,0.9938398357289527
deepseek-v3-8000,0.319693094629156,625,81,219,299,0.48,60,437,21,0.9136029411764706,40,444,0,1.0
huggingface-gemma-2-9b-it-4096,0,0,0,0,0,0,0,0,0,0,0,0,0,0
huggingface-gemma-2-9b-it-512,0,0,0,0,0,0,0,0,0,0,0,0,0,0
together-Llama-3.3-70B-Instruct-8000,0.17647058823529413,625,39,235,301,0.4384,26,470,40,0.8464163822525598,24,533,3,0.9946428571428572
openai-gpt4o-mini-8000,0.13567362428842505,1651,78,666,1013,0.4506359781950333,42,1480,157,0.9675778766687858,47,1484,0,1.0
google-gemini-2.0-flash-exp-8000,0.27877237851662406,625,96,202,304,0.4768,40,436,30,0.8998109640831758,33,452,4,0.9918200408997955
huggingface-Qwen2.5-72B-GeoGPT-8000,0.15089514066496162,625,39,177,259,0.3456,24,397,15,0.7184300341296929,16,546,0,1.0
deepseek-r1-8000,0.3657289002557545,625,105,198,288,0.4848,60,401,25,0.8865384615384615,37,420,3,0.9934782608695653
huggingface-Qwen2.5-3B-Instruct-8000,0,0,0,0,0,0,0,0,0,0,0,0,0,0
huggingface-gemma-2-9b-it-8000,0,0,0,0,0,0,0,0,0,0,0,0,0,0
together-Qwen2.5-7B-Instruct-Turbo-8000,0.1278772378516624,625,34,244,291,0.4448,16,494,25,0.8629441624365483,12,561,2,0.9965217391304347
together-Qwen3-235B-A22B-fp8-tput-30000,0.329923273657289,625,106,209,297,0.504,41,439,26,0.9248554913294798,46,431,1,0.997907949790795
together-Llama-3.1-405B-Instruct-Turbo-8000,0.1329923273657289,625,28,200,239,0.3648,18,395,26,0.6917922948073701,21,557,1,0.998272884283247
